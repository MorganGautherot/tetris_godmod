{"cells":[{"cell_type":"markdown","metadata":{"id":"dsIgDQsMVazd"},"source":["# Importation des packages"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10117,"status":"ok","timestamp":1703171594627,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"8bQJRO0WJrFI"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import pickle\n","import os\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","\n","import cv2\n","import math\n","from glob import glob"]},{"cell_type":"markdown","metadata":{"id":"xIFvHo8cVhA5"},"source":["# Syncrhonisation avec Google Drive"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21390,"status":"ok","timestamp":1703171616015,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"8EUCUxUuVfoq","outputId":"fb1d2f70-6dd9-4535-c746-4cf32f6746b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"NVHWXt4JZAkL"},"source":["# Variables d'environnement"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703171616015,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"fs304ttfZAK5"},"outputs":[],"source":["PATH_DATA = 'gdrive/MyDrive/AIForYou/Datasets/supervisée/classification/non_structurée/Tetris/first_line/'"]},{"cell_type":"markdown","metadata":{"id":"EWymtw4oVdV9"},"source":["# Importation des données"]},{"cell_type":"markdown","metadata":{"id":"NG_QQFWo2QPN"},"source":["# Chargement des données sauvegardées"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":769,"status":"ok","timestamp":1703172506706,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"loOCAalw2SkX","outputId":"5994959f-72f7-4b54-a38c-0e460915fe6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(84516, 4)"]},"metadata":{},"execution_count":28}],"source":["training_data = pd.read_csv(f'{PATH_DATA}train_data-first_line.csv')\n","training_data.shape"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1703172508099,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"0IDUjy0Y2Wo-","outputId":"36cc62c3-9c1d-47bb-e5e3-1bc924fd1481"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1119, 4)"]},"metadata":{},"execution_count":29}],"source":["testing_data = pd.read_csv(f'{PATH_DATA}test_data-first_line.csv')\n","testing_data.shape"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1408,"status":"ok","timestamp":1703172510101,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"VcXBl8pcFE6t","outputId":"697163c7-abfd-458d-8e2d-624519e3fed5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(84516, 20, 10, 1)"]},"metadata":{},"execution_count":30}],"source":["training_data_images = np.load(f'{PATH_DATA}train_data_images-first_line.npy')\n","training_data_images.shape"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703172510101,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"7f9dVHoR8w-p","outputId":"ef286667-b821-4eb5-9599-becf9c19680d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1119, 20, 10, 1)"]},"metadata":{},"execution_count":31}],"source":["testing_data_images = np.load(f'{PATH_DATA}test_data_images-first_line.npy')\n","testing_data_images.shape"]},{"cell_type":"markdown","metadata":{"id":"pNsms8OVmMqG"},"source":["# Mettre les labels au bon format"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703172510101,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"isobmQ5UmP-u"},"outputs":[],"source":["def output_form(data):\n","    column = data.pop('column')\n","    column = list(map(lambda x : int(x), column))\n","    column = to_categorical(column)\n","    column = np.array(column)\n","    rotation = data.pop('rotation')\n","    rotation = list(map(lambda x : int(x), rotation))\n","    rotation = to_categorical(rotation)\n","    rotation = np.array(rotation)\n","    return (rotation, column)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703172510101,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"cDbxrrHlmYYn"},"outputs":[],"source":["y_train = output_form(training_data.loc[:, ['column', 'rotation']])"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1703172510538,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"yQHbkjvIum9s"},"outputs":[],"source":["new_train = np.zeros([training_data.shape[0], 40])\n","cmpt = 0\n","for rot, col in zip(y_train[0], y_train[1]):\n","\n","  new_train[cmpt, :] = np.dot(rot.T.reshape(-1, 1), col.reshape(1, -1)).flatten()\n","  cmpt += 1"]},{"cell_type":"code","source":["np.sum(new_train, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjxhm0qMjfMq","executionInfo":{"status":"ok","timestamp":1703172510538,"user_tz":-60,"elapsed":4,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"}},"outputId":"bd0883b9-8b9d-4e4b-9b33-b01ae86fc536"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., ..., 1., 1., 1.])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703172510538,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"RO1wwI43mjA0"},"outputs":[],"source":["y_test = output_form(testing_data.loc[:, ['column', 'rotation']])"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703172510538,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"qsgSf56Rrv29"},"outputs":[],"source":["new_test = np.zeros([testing_data.shape[0], 40])\n","cmpt = 0\n","for rot, col in zip(y_test[0], y_test[1]):\n","\n","  new_test[cmpt, :] = np.dot(rot.T.reshape(-1, 1), col.reshape(1, -1)).flatten()\n","  cmpt += 1"]},{"cell_type":"code","source":["np.sum(new_test, axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ct6eMqvAjZTm","executionInfo":{"status":"ok","timestamp":1703172510538,"user_tz":-60,"elapsed":4,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"}},"outputId":"818a0cb8-1623-4f06-c74e-f1cd8472152e"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 1., 1., ..., 1., 1., 1.])"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["# Distribution des données"],"metadata":{"id":"vsJCxQpUIBNZ"}},{"cell_type":"code","source":["np.sum(new_train, axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oDLaeQ3ICLP","executionInfo":{"status":"ok","timestamp":1703172510539,"user_tz":-60,"elapsed":3,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"}},"outputId":"1e3d666f-94f5-46f1-8537-e28b9c651c1e"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([10389.,  5145.,  5568.,  6167.,  6111.,  5669.,  6252.,  7004.,\n","        2412.,     0.,  5850.,   688.,  1241.,  1517.,  1339.,  1456.,\n","        1458.,   858.,  2440.,  1478.,  1155.,   445.,   731.,   797.,\n","         733.,   677.,   404.,  1138.,     0.,     0.,   600.,   182.,\n","         398.,   331.,   343.,   391.,   317.,   151.,  2681.,     0.])"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"t2dnDJggazV_"},"source":["# Création des générateurs"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703172511226,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"oT4FHp0B2IDL"},"outputs":[],"source":["class image_generator():\n","\n","    # Class is a dataset wrapper for better training performance\n","    def __init__(self, image_list, target_list, norm=False, batch_size=8, shuffle=True, data_aug=True, no_whole=False):\n","        self.image_list = image_list\n","        self.target_list = target_list\n","        self.id_list = np.arange(image_list.shape[0])\n","        self.batch_size = batch_size\n","        self.len = math.ceil(len(self.image_list) / self.batch_size)\n","        self.idx = 0\n","        self.shuffle = shuffle\n","        self.norm = norm\n","        self.no_whole = no_whole\n","        self.data_aug = data_aug\n","        if self.shuffle :\n","            np.random.shuffle(self.id_list)\n","\n","    def __norm__(self, batch):\n","        return np.array([ (x - np.min(x) )/ (np.max(x) - np.min(x)) for x in batch])\n","\n","    def __getitem__(self):\n","        if (self.idx + 1) * self.batch_size > len(self.image_list) :\n","            idx_end = len(self.image_list)\n","        else :\n","            idx_end = (self.idx + 1) * self.batch_size\n","\n","\n","        id_list_batch = self.id_list[self.idx * self.batch_size:idx_end]\n","        batch_img = self.image_list[id_list_batch]\n","\n","        if self.norm :\n","            batch_img = self.__norm__(batch_img)\n","\n","        if self.data_aug:\n","            batch_img = np.array([self.data_augmentation(x)for x in batch_img])\n","\n","        if self.no_whole:\n","            batch_img = np.array([self.no_whole(x)for x in batch_img])\n","\n","        return batch_img\n","\n","    def __gettarget__(self):\n","        if (self.idx + 1) * self.batch_size > len(self.image_list) :\n","            idx_end = len(self.image_list)\n","        else :\n","            idx_end = (self.idx + 1) * self.batch_size\n","\n","        id_list_batch = self.id_list[self.idx * self.batch_size:idx_end]\n","\n","        target_batch = self.target_list[id_list_batch]\n","\n","\n","        return target_batch\n","\n","\n","\n","    def __getbatch__(self):\n","        batch = self.__getitem__()\n","\n","        x = np.array(batch)\n","        y = self.__gettarget__()\n","        return x, y\n","\n","    # Generate flow of data\n","    def loader(self):\n","        # load data from somwhere with Python, and yield them\n","        while True:\n","            batch_input, batch_output = self.__getbatch__()\n","            self.__iter__()\n","            yield (batch_input, batch_output)\n","\n","    def __iter__(self):\n","        if self.idx + 2 > self.len :\n","            self.idx = 0\n","            if self.shuffle :\n","                np.random.shuffle(self.id_list)\n","        else :\n","            self.idx += 1\n","\n","    def get_len(self):\n","        return self.len\n","\n","    def get_minimum_maximum_height(self, game_matrix):\n","        lines, columns, _ = game_matrix.shape\n","        minimum_height = np.inf\n","        maximum_height = -np.inf\n","        for column in np.arange(columns):\n","          for line in np.arange(2,lines):\n","            if game_matrix[line, column, 0] == 1 :\n","\n","              if lines-line < minimum_height:\n","                minimum_height = lines-line\n","              if lines-line > maximum_height:\n","                maximum_height = lines-line\n","              break\n","\n","        if minimum_height == np.inf or maximum_height==-np.inf:\n","          maximum_height = 0\n","          minimum_height = 0\n","        return maximum_height, minimum_height\n","\n","    def increase_row(self, game_matrix, maximum_height):\n","\n","      number_row = np.random.randint(18-maximum_height+1)\n","\n","      new_game_matrix = np.zeros(game_matrix.shape)\n","\n","      new_game_matrix[:2, :, :] = game_matrix[:2, :, :]\n","\n","      new_game_matrix[20-maximum_height-number_row:20-number_row, :, :] = game_matrix[20-maximum_height:, :, :]\n","\n","      new_game_matrix[20-number_row:, :, :] = 1\n","\n","      return new_game_matrix\n","\n","    def reduce_row(self, game_matrix, minimum_height, maximum_height):\n","\n","      number_row = np.random.randint(minimum_height+1)\n","\n","      new_game_matrix = np.zeros(game_matrix.shape)\n","\n","      new_game_matrix[:2, :, :] = game_matrix[:2, :, :]\n","\n","      new_game_matrix[-((maximum_height-number_row)):, :, :] = game_matrix[20-maximum_height:20-number_row, :, :]\n","\n","      return new_game_matrix\n","\n","\n","    def data_augmentation(self, game_matrix):\n","\n","      maximum_height, minimum_height = self.get_minimum_maximum_height(game_matrix)\n","\n","\n","      add_row = np.random.randint(2)\n","\n","      if add_row and maximum_height<18 :\n","        game_matrix = self.increase_row(game_matrix, maximum_height)\n","\n","\n","      elif not(add_row) and minimum_height>0 and maximum_height>minimum_height:\n","\n","        game_matrix = self.reduce_row(game_matrix, minimum_height, maximum_height)\n","        maximum_height, minimum_height = self.get_minimum_maximum_height(game_matrix)\n","\n","\n","      return game_matrix\n","\n","    def no_whole(self, game_matrix):\n","\n","      gamme_matrix_without_current_tetromino = game_matrix.copy()\n","\n","      width, colmun, _ = gamme_matrix_without_current_tetromino.shape\n","\n","      for col in np.arange(colmun):\n","        first_tetromino = np.argmax(gamme_matrix_without_current_tetromino[2:, col, :])\n","\n","        gamme_matrix_without_current_tetromino[first_tetromino:, col, :]=1\n","\n","      return gamme_matrix_without_current_tetromino\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703172520141,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"23u4hmO7FuTD"},"outputs":[],"source":["train_datagen = image_generator(training_data_images, new_train, batch_size=512, norm=False, data_aug=True, no_whole=False, shuffle=True)\n","test_datagen = image_generator(testing_data_images, new_test, batch_size=512, norm=False, data_aug=False, no_whole=False, shuffle=True)"]},{"cell_type":"code","source":[],"metadata":{"id":"eGzlxuidiaPY","executionInfo":{"status":"ok","timestamp":1703172512600,"user_tz":-60,"elapsed":1,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1703172522838,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"oP-IkEnj4mUg","outputId":"8c46a44f-7d74-4e70-fb15-47a3c9a45809"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n","(512, 20, 10, 1)\n","(512, 40)\n","[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]]\n","(512, 20, 10, 1)\n","(512, 40)\n","[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 1. 1. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 1. 0. 1. 0. 0. 1. 0.]\n"," [0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n","(512, 20, 10, 1)\n","(512, 40)\n","[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]]\n","(512, 20, 10, 1)\n","(512, 40)\n","[[0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n","(512, 20, 10, 1)\n","(512, 40)\n"]}],"source":["for i in range(5):\n","  x, y = next(train_datagen.loader())\n","  print(x[0, :, :, 0])\n","  print(x.shape)\n","  print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"r6G5M8zflpFc"},"source":["# Initialisation du modèle"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703171623712,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"HcFhv6EmvPDh"},"outputs":[],"source":["def base_model(inputs):\n","  x = tf.keras.layers.ZeroPadding2D(padding=(2, 2))(inputs)\n","  x = tf.keras.layers.Conv2D(8, (3, 3), padding=\"same\", activation='relu')(x)\n","  x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n","  #x = tf.keras.layers.Dropout(0.1)(x)\n","  x = tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation='relu')(x)\n","  x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n","  #x = tf.keras.layers.Dropout(0.1)(x)\n","  x = tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu')(x)\n","  x = tf.keras.layers.AveragePooling2D((2, 2))(x)\n","  x = tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu')(x)\n","  x = tf.keras.layers.Flatten()(x)\n","  #x = tf.keras.layers.Dense(64, activation='relu')(x)\n","  #x = tf.keras.layers.Dropout(0.1)(x)\n","  x = tf.keras.layers.Dense(64, activation='relu')(x)\n","  #x = tf.keras.layers.Dropout(0.1)(x)\n","  output = tf.keras.layers.Dense(units = '40', activation = 'softmax')(x)\n","  model = tf.keras.models.Model(inputs=inputs, outputs = output)\n","\n","  return model"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703171623712,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"IINoy0oAvg2p"},"outputs":[],"source":["inputs = tf.keras.layers.Input(shape=(20, 10, 1))"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1703171624945,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"GZGyiWuuveiw"},"outputs":[],"source":["model = base_model(inputs)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703171624946,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"MNKv1bq4UfuG"},"outputs":[],"source":["\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","             loss = tf.keras.losses.CategoricalCrossentropy(),\n","             metrics=tf.keras.metrics.AUC())"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703171624946,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"SO6yFk5uKBSn","outputId":"a56c5ab7-1a34-49b7-bc7b-347cdc6726ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20, 10, 1)]       0         \n","                                                                 \n"," zero_padding2d (ZeroPaddin  (None, 24, 14, 1)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d (Conv2D)             (None, 24, 14, 8)         80        \n","                                                                 \n"," average_pooling2d (Average  (None, 12, 7, 8)          0         \n"," Pooling2D)                                                      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 12, 7, 16)         1168      \n","                                                                 \n"," average_pooling2d_1 (Avera  (None, 6, 3, 16)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 6, 3, 32)          4640      \n","                                                                 \n"," average_pooling2d_2 (Avera  (None, 3, 1, 32)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 3, 1, 64)          18496     \n","                                                                 \n"," flatten (Flatten)           (None, 192)               0         \n","                                                                 \n"," dense (Dense)               (None, 64)                12352     \n","                                                                 \n"," dense_1 (Dense)             (None, 40)                2600      \n","                                                                 \n","=================================================================\n","Total params: 39336 (153.66 KB)\n","Trainable params: 39336 (153.66 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"KVM-SXzel026"},"source":["# Entraînement du moèle"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703171624947,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"ljfkEDUk55o-"},"outputs":[],"source":["PATH_model = 'gdrive/MyDrive/AIForYou/applications/tetris/training_model/checkpoint_epoch-{epoch}_val_loss-{val_loss:.4f}.hdf5'"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":958,"status":"ok","timestamp":1703171625901,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"kQdtDuar51ku"},"outputs":[],"source":["callback = tf.keras.callbacks.ModelCheckpoint(PATH_model, monitor=\"val_loss\", mode=\"min\", save_best_only=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703171626323,"user":{"displayName":"Gautherot Morgan","userId":"07974205866322024288"},"user_tz":-60},"id":"ZUWh4BxOFGW-"},"outputs":[],"source":["model.load_weights('gdrive/MyDrive/AIForYou/applications/tetris/training_model/checkpoint_epoch-209_val_loss-1.4781.hdf5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQLtHomnSd46","outputId":"55b4f373-2614-4387-fd09-898f226a8585"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 228/10000\n","166/166 [==============================] - 17s 102ms/step - loss: 1.5920 - auc: 0.9603 - val_loss: 1.5202 - val_auc: 0.9637\n","Epoch 229/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5893 - auc: 0.9602 - val_loss: 1.4729 - val_auc: 0.9645\n","Epoch 230/10000\n","  1/166 [..............................] - ETA: 3s - loss: 1.6778 - auc: 0.9540"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["166/166 [==============================] - 17s 100ms/step - loss: 1.5930 - auc: 0.9602 - val_loss: 1.4870 - val_auc: 0.9649\n","Epoch 231/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5947 - auc: 0.9602 - val_loss: 1.4752 - val_auc: 0.9648\n","Epoch 232/10000\n","166/166 [==============================] - 15s 91ms/step - loss: 1.5917 - auc: 0.9603 - val_loss: 1.4860 - val_auc: 0.9651\n","Epoch 233/10000\n","166/166 [==============================] - 15s 91ms/step - loss: 1.5931 - auc: 0.9601 - val_loss: 1.4904 - val_auc: 0.9657\n","Epoch 234/10000\n","166/166 [==============================] - 15s 91ms/step - loss: 1.5856 - auc: 0.9605 - val_loss: 1.4751 - val_auc: 0.9655\n","Epoch 235/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5907 - auc: 0.9603 - val_loss: 1.4891 - val_auc: 0.9640\n","Epoch 236/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5914 - auc: 0.9603 - val_loss: 1.5262 - val_auc: 0.9630\n","Epoch 237/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5865 - auc: 0.9605 - val_loss: 1.5401 - val_auc: 0.9613\n","Epoch 238/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5861 - auc: 0.9606 - val_loss: 1.4815 - val_auc: 0.9646\n","Epoch 239/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5863 - auc: 0.9605 - val_loss: 1.4729 - val_auc: 0.9651\n","Epoch 240/10000\n","166/166 [==============================] - 15s 91ms/step - loss: 1.5862 - auc: 0.9606 - val_loss: 1.4913 - val_auc: 0.9647\n","Epoch 241/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5844 - auc: 0.9607 - val_loss: 1.4822 - val_auc: 0.9649\n","Epoch 242/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5843 - auc: 0.9606 - val_loss: 1.4884 - val_auc: 0.9639\n","Epoch 243/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5790 - auc: 0.9608 - val_loss: 1.4866 - val_auc: 0.9638\n","Epoch 244/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5778 - auc: 0.9609 - val_loss: 1.4744 - val_auc: 0.9657\n","Epoch 245/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5836 - auc: 0.9607 - val_loss: 1.4633 - val_auc: 0.9667\n","Epoch 246/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5839 - auc: 0.9606 - val_loss: 1.4839 - val_auc: 0.9633\n","Epoch 247/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5803 - auc: 0.9608 - val_loss: 1.4956 - val_auc: 0.9650\n","Epoch 248/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5770 - auc: 0.9612 - val_loss: 1.4762 - val_auc: 0.9649\n","Epoch 249/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5784 - auc: 0.9611 - val_loss: 1.4964 - val_auc: 0.9637\n","Epoch 250/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5769 - auc: 0.9609 - val_loss: 1.4930 - val_auc: 0.9652\n","Epoch 251/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5791 - auc: 0.9608 - val_loss: 1.4327 - val_auc: 0.9678\n","Epoch 252/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5737 - auc: 0.9610 - val_loss: 1.4679 - val_auc: 0.9670\n","Epoch 253/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5712 - auc: 0.9613 - val_loss: 1.4480 - val_auc: 0.9664\n","Epoch 254/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5716 - auc: 0.9613 - val_loss: 1.5022 - val_auc: 0.9627\n","Epoch 255/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5704 - auc: 0.9614 - val_loss: 1.4706 - val_auc: 0.9656\n","Epoch 256/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5705 - auc: 0.9613 - val_loss: 1.4503 - val_auc: 0.9664\n","Epoch 257/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5664 - auc: 0.9614 - val_loss: 1.4697 - val_auc: 0.9663\n","Epoch 258/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5651 - auc: 0.9616 - val_loss: 1.4861 - val_auc: 0.9649\n","Epoch 259/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5656 - auc: 0.9616 - val_loss: 1.4783 - val_auc: 0.9632\n","Epoch 260/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.5664 - auc: 0.9615 - val_loss: 1.4780 - val_auc: 0.9651\n","Epoch 261/10000\n","166/166 [==============================] - 18s 106ms/step - loss: 1.5624 - auc: 0.9618 - val_loss: 1.4429 - val_auc: 0.9659\n","Epoch 262/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5669 - auc: 0.9613 - val_loss: 1.4637 - val_auc: 0.9658\n","Epoch 263/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5680 - auc: 0.9614 - val_loss: 1.4592 - val_auc: 0.9651\n","Epoch 264/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5634 - auc: 0.9617 - val_loss: 1.4806 - val_auc: 0.9660\n","Epoch 265/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5620 - auc: 0.9619 - val_loss: 1.4426 - val_auc: 0.9670\n","Epoch 266/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5585 - auc: 0.9620 - val_loss: 1.4799 - val_auc: 0.9654\n","Epoch 267/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5606 - auc: 0.9620 - val_loss: 1.4781 - val_auc: 0.9657\n","Epoch 268/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5640 - auc: 0.9616 - val_loss: 1.4544 - val_auc: 0.9679\n","Epoch 269/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5572 - auc: 0.9621 - val_loss: 1.4626 - val_auc: 0.9655\n","Epoch 270/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5572 - auc: 0.9621 - val_loss: 1.4453 - val_auc: 0.9658\n","Epoch 271/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5564 - auc: 0.9621 - val_loss: 1.4694 - val_auc: 0.9664\n","Epoch 272/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5587 - auc: 0.9619 - val_loss: 1.5032 - val_auc: 0.9631\n","Epoch 273/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5557 - auc: 0.9620 - val_loss: 1.4996 - val_auc: 0.9637\n","Epoch 274/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.5553 - auc: 0.9619 - val_loss: 1.4166 - val_auc: 0.9688\n","Epoch 275/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5541 - auc: 0.9621 - val_loss: 1.4519 - val_auc: 0.9666\n","Epoch 276/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5546 - auc: 0.9621 - val_loss: 1.4605 - val_auc: 0.9654\n","Epoch 277/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5540 - auc: 0.9622 - val_loss: 1.4385 - val_auc: 0.9678\n","Epoch 278/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5527 - auc: 0.9622 - val_loss: 1.4975 - val_auc: 0.9628\n","Epoch 279/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5492 - auc: 0.9623 - val_loss: 1.4579 - val_auc: 0.9668\n","Epoch 280/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5535 - auc: 0.9621 - val_loss: 1.4575 - val_auc: 0.9659\n","Epoch 281/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5481 - auc: 0.9624 - val_loss: 1.4216 - val_auc: 0.9669\n","Epoch 282/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5481 - auc: 0.9624 - val_loss: 1.4280 - val_auc: 0.9669\n","Epoch 283/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5487 - auc: 0.9623 - val_loss: 1.4358 - val_auc: 0.9675\n","Epoch 284/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5480 - auc: 0.9625 - val_loss: 1.4333 - val_auc: 0.9691\n","Epoch 285/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5425 - auc: 0.9625 - val_loss: 1.4449 - val_auc: 0.9656\n","Epoch 286/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5420 - auc: 0.9628 - val_loss: 1.4342 - val_auc: 0.9679\n","Epoch 287/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.5484 - auc: 0.9624 - val_loss: 1.4674 - val_auc: 0.9670\n","Epoch 288/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.5436 - auc: 0.9628 - val_loss: 1.4301 - val_auc: 0.9686\n","Epoch 289/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5418 - auc: 0.9628 - val_loss: 1.4815 - val_auc: 0.9652\n","Epoch 290/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.5415 - auc: 0.9628 - val_loss: 1.4443 - val_auc: 0.9667\n","Epoch 291/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5375 - auc: 0.9631 - val_loss: 1.4603 - val_auc: 0.9658\n","Epoch 292/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5431 - auc: 0.9627 - val_loss: 1.4521 - val_auc: 0.9667\n","Epoch 293/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5411 - auc: 0.9628 - val_loss: 1.4182 - val_auc: 0.9677\n","Epoch 294/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5400 - auc: 0.9627 - val_loss: 1.4355 - val_auc: 0.9680\n","Epoch 295/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.5412 - auc: 0.9627 - val_loss: 1.4626 - val_auc: 0.9651\n","Epoch 296/10000\n","166/166 [==============================] - 19s 115ms/step - loss: 1.5390 - auc: 0.9630 - val_loss: 1.4315 - val_auc: 0.9672\n","Epoch 297/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5366 - auc: 0.9630 - val_loss: 1.4342 - val_auc: 0.9665\n","Epoch 298/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.5373 - auc: 0.9631 - val_loss: 1.4492 - val_auc: 0.9635\n","Epoch 299/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5346 - auc: 0.9630 - val_loss: 1.4373 - val_auc: 0.9676\n","Epoch 300/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5359 - auc: 0.9630 - val_loss: 1.4287 - val_auc: 0.9683\n","Epoch 301/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5342 - auc: 0.9630 - val_loss: 1.4289 - val_auc: 0.9665\n","Epoch 302/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5383 - auc: 0.9629 - val_loss: 1.4407 - val_auc: 0.9676\n","Epoch 303/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5327 - auc: 0.9632 - val_loss: 1.4358 - val_auc: 0.9675\n","Epoch 304/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5318 - auc: 0.9632 - val_loss: 1.4243 - val_auc: 0.9684\n","Epoch 305/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5325 - auc: 0.9630 - val_loss: 1.4656 - val_auc: 0.9646\n","Epoch 306/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5309 - auc: 0.9632 - val_loss: 1.4189 - val_auc: 0.9698\n","Epoch 307/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5328 - auc: 0.9633 - val_loss: 1.4398 - val_auc: 0.9672\n","Epoch 308/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.5269 - auc: 0.9634 - val_loss: 1.4078 - val_auc: 0.9695\n","Epoch 309/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5274 - auc: 0.9634 - val_loss: 1.4303 - val_auc: 0.9672\n","Epoch 310/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5265 - auc: 0.9636 - val_loss: 1.4504 - val_auc: 0.9659\n","Epoch 311/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5304 - auc: 0.9633 - val_loss: 1.4242 - val_auc: 0.9669\n","Epoch 312/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5238 - auc: 0.9635 - val_loss: 1.4213 - val_auc: 0.9678\n","Epoch 313/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5287 - auc: 0.9635 - val_loss: 1.4237 - val_auc: 0.9675\n","Epoch 314/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5254 - auc: 0.9636 - val_loss: 1.4032 - val_auc: 0.9689\n","Epoch 315/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5263 - auc: 0.9634 - val_loss: 1.4376 - val_auc: 0.9673\n","Epoch 316/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.5235 - auc: 0.9636 - val_loss: 1.4020 - val_auc: 0.9677\n","Epoch 317/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5256 - auc: 0.9635 - val_loss: 1.4466 - val_auc: 0.9680\n","Epoch 318/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5229 - auc: 0.9636 - val_loss: 1.3865 - val_auc: 0.9705\n","Epoch 319/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5230 - auc: 0.9636 - val_loss: 1.4500 - val_auc: 0.9668\n","Epoch 320/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5200 - auc: 0.9638 - val_loss: 1.4041 - val_auc: 0.9691\n","Epoch 321/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5192 - auc: 0.9640 - val_loss: 1.4899 - val_auc: 0.9636\n","Epoch 322/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5248 - auc: 0.9636 - val_loss: 1.4371 - val_auc: 0.9668\n","Epoch 323/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5209 - auc: 0.9636 - val_loss: 1.4090 - val_auc: 0.9674\n","Epoch 324/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5178 - auc: 0.9638 - val_loss: 1.4172 - val_auc: 0.9684\n","Epoch 325/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5212 - auc: 0.9638 - val_loss: 1.4106 - val_auc: 0.9667\n","Epoch 326/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5197 - auc: 0.9639 - val_loss: 1.4490 - val_auc: 0.9662\n","Epoch 327/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5186 - auc: 0.9639 - val_loss: 1.4487 - val_auc: 0.9663\n","Epoch 328/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5229 - auc: 0.9637 - val_loss: 1.4537 - val_auc: 0.9642\n","Epoch 329/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5180 - auc: 0.9639 - val_loss: 1.4488 - val_auc: 0.9683\n","Epoch 330/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5133 - auc: 0.9642 - val_loss: 1.4304 - val_auc: 0.9679\n","Epoch 331/10000\n","166/166 [==============================] - 19s 116ms/step - loss: 1.5177 - auc: 0.9638 - val_loss: 1.4237 - val_auc: 0.9680\n","Epoch 332/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5179 - auc: 0.9638 - val_loss: 1.4344 - val_auc: 0.9675\n","Epoch 333/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5164 - auc: 0.9639 - val_loss: 1.4208 - val_auc: 0.9677\n","Epoch 334/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5098 - auc: 0.9643 - val_loss: 1.4636 - val_auc: 0.9659\n","Epoch 335/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5087 - auc: 0.9644 - val_loss: 1.4207 - val_auc: 0.9684\n","Epoch 336/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5127 - auc: 0.9641 - val_loss: 1.4194 - val_auc: 0.9687\n","Epoch 337/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5087 - auc: 0.9644 - val_loss: 1.4121 - val_auc: 0.9680\n","Epoch 338/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5095 - auc: 0.9643 - val_loss: 1.4095 - val_auc: 0.9694\n","Epoch 339/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5161 - auc: 0.9641 - val_loss: 1.4438 - val_auc: 0.9662\n","Epoch 340/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5112 - auc: 0.9644 - val_loss: 1.4378 - val_auc: 0.9651\n","Epoch 341/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.5069 - auc: 0.9646 - val_loss: 1.3838 - val_auc: 0.9716\n","Epoch 342/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5097 - auc: 0.9643 - val_loss: 1.4357 - val_auc: 0.9683\n","Epoch 343/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5083 - auc: 0.9645 - val_loss: 1.4428 - val_auc: 0.9666\n","Epoch 344/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5076 - auc: 0.9643 - val_loss: 1.4180 - val_auc: 0.9669\n","Epoch 345/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5104 - auc: 0.9642 - val_loss: 1.4251 - val_auc: 0.9669\n","Epoch 346/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.5067 - auc: 0.9645 - val_loss: 1.4209 - val_auc: 0.9682\n","Epoch 347/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5027 - auc: 0.9647 - val_loss: 1.4789 - val_auc: 0.9645\n","Epoch 348/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.5057 - auc: 0.9644 - val_loss: 1.3743 - val_auc: 0.9701\n","Epoch 349/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.4998 - auc: 0.9648 - val_loss: 1.4034 - val_auc: 0.9683\n","Epoch 350/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5016 - auc: 0.9647 - val_loss: 1.4015 - val_auc: 0.9692\n","Epoch 351/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.5064 - auc: 0.9644 - val_loss: 1.4407 - val_auc: 0.9678\n","Epoch 352/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5019 - auc: 0.9645 - val_loss: 1.4462 - val_auc: 0.9663\n","Epoch 353/10000\n","166/166 [==============================] - 15s 91ms/step - loss: 1.5052 - auc: 0.9644 - val_loss: 1.4138 - val_auc: 0.9687\n","Epoch 354/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5002 - auc: 0.9646 - val_loss: 1.3884 - val_auc: 0.9722\n","Epoch 355/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5000 - auc: 0.9650 - val_loss: 1.4186 - val_auc: 0.9675\n","Epoch 356/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.4967 - auc: 0.9648 - val_loss: 1.4316 - val_auc: 0.9671\n","Epoch 357/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5032 - auc: 0.9647 - val_loss: 1.4013 - val_auc: 0.9692\n","Epoch 358/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.5002 - auc: 0.9648 - val_loss: 1.4286 - val_auc: 0.9669\n","Epoch 359/10000\n","166/166 [==============================] - 18s 109ms/step - loss: 1.5040 - auc: 0.9648 - val_loss: 1.4238 - val_auc: 0.9682\n","Epoch 360/10000\n","166/166 [==============================] - 15s 92ms/step - loss: 1.4974 - auc: 0.9649 - val_loss: 1.4106 - val_auc: 0.9673\n","Epoch 361/10000\n","166/166 [==============================] - 15s 90ms/step - loss: 1.5023 - auc: 0.9646 - val_loss: 1.4110 - val_auc: 0.9673\n","Epoch 362/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.4923 - auc: 0.9652 - val_loss: 1.4015 - val_auc: 0.9688\n","Epoch 363/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.4965 - auc: 0.9650 - val_loss: 1.3694 - val_auc: 0.9703\n","Epoch 364/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.4956 - auc: 0.9650 - val_loss: 1.3995 - val_auc: 0.9692\n","Epoch 365/10000\n","166/166 [==============================] - 15s 91ms/step - loss: 1.4970 - auc: 0.9647 - val_loss: 1.4389 - val_auc: 0.9661\n","Epoch 366/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4970 - auc: 0.9648 - val_loss: 1.3732 - val_auc: 0.9694\n","Epoch 367/10000\n","166/166 [==============================] - 20s 118ms/step - loss: 1.4943 - auc: 0.9650 - val_loss: 1.4218 - val_auc: 0.9688\n","Epoch 368/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4948 - auc: 0.9650 - val_loss: 1.4333 - val_auc: 0.9673\n","Epoch 369/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.4957 - auc: 0.9651 - val_loss: 1.4103 - val_auc: 0.9681\n","Epoch 370/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4920 - auc: 0.9653 - val_loss: 1.3984 - val_auc: 0.9697\n","Epoch 371/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.4951 - auc: 0.9650 - val_loss: 1.3973 - val_auc: 0.9669\n","Epoch 372/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4940 - auc: 0.9650 - val_loss: 1.4196 - val_auc: 0.9681\n","Epoch 373/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4939 - auc: 0.9651 - val_loss: 1.4023 - val_auc: 0.9683\n","Epoch 374/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4925 - auc: 0.9650 - val_loss: 1.4051 - val_auc: 0.9692\n","Epoch 375/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4885 - auc: 0.9653 - val_loss: 1.4288 - val_auc: 0.9663\n","Epoch 376/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4891 - auc: 0.9652 - val_loss: 1.4080 - val_auc: 0.9684\n","Epoch 377/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4910 - auc: 0.9652 - val_loss: 1.3964 - val_auc: 0.9681\n","Epoch 378/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4903 - auc: 0.9651 - val_loss: 1.4046 - val_auc: 0.9691\n","Epoch 379/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4877 - auc: 0.9655 - val_loss: 1.3954 - val_auc: 0.9689\n","Epoch 380/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4884 - auc: 0.9652 - val_loss: 1.4333 - val_auc: 0.9677\n","Epoch 381/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4920 - auc: 0.9651 - val_loss: 1.4108 - val_auc: 0.9678\n","Epoch 382/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4884 - auc: 0.9653 - val_loss: 1.3892 - val_auc: 0.9701\n","Epoch 383/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4866 - auc: 0.9654 - val_loss: 1.3692 - val_auc: 0.9701\n","Epoch 384/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4872 - auc: 0.9655 - val_loss: 1.4067 - val_auc: 0.9686\n","Epoch 385/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4882 - auc: 0.9653 - val_loss: 1.3947 - val_auc: 0.9701\n","Epoch 386/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.4854 - auc: 0.9652 - val_loss: 1.3914 - val_auc: 0.9699\n","Epoch 387/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4854 - auc: 0.9654 - val_loss: 1.3853 - val_auc: 0.9696\n","Epoch 388/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4861 - auc: 0.9654 - val_loss: 1.3894 - val_auc: 0.9689\n","Epoch 389/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4862 - auc: 0.9653 - val_loss: 1.4287 - val_auc: 0.9656\n","Epoch 390/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4832 - auc: 0.9653 - val_loss: 1.3850 - val_auc: 0.9699\n","Epoch 391/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.4821 - auc: 0.9656 - val_loss: 1.3970 - val_auc: 0.9687\n","Epoch 392/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.4827 - auc: 0.9656 - val_loss: 1.3847 - val_auc: 0.9696\n","Epoch 393/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4810 - auc: 0.9656 - val_loss: 1.4395 - val_auc: 0.9689\n","Epoch 394/10000\n","166/166 [==============================] - 17s 102ms/step - loss: 1.4832 - auc: 0.9654 - val_loss: 1.4084 - val_auc: 0.9697\n","Epoch 395/10000\n","166/166 [==============================] - 17s 101ms/step - loss: 1.4862 - auc: 0.9654 - val_loss: 1.3970 - val_auc: 0.9700\n","Epoch 396/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4832 - auc: 0.9655 - val_loss: 1.4169 - val_auc: 0.9680\n","Epoch 397/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4787 - auc: 0.9658 - val_loss: 1.3879 - val_auc: 0.9689\n","Epoch 398/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4797 - auc: 0.9657 - val_loss: 1.3897 - val_auc: 0.9702\n","Epoch 399/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4816 - auc: 0.9657 - val_loss: 1.4069 - val_auc: 0.9691\n","Epoch 400/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4819 - auc: 0.9657 - val_loss: 1.3998 - val_auc: 0.9689\n","Epoch 401/10000\n","166/166 [==============================] - 19s 118ms/step - loss: 1.4798 - auc: 0.9657 - val_loss: 1.3770 - val_auc: 0.9717\n","Epoch 402/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.4827 - auc: 0.9655 - val_loss: 1.4004 - val_auc: 0.9691\n","Epoch 403/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4767 - auc: 0.9659 - val_loss: 1.3999 - val_auc: 0.9684\n","Epoch 404/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.4841 - auc: 0.9654 - val_loss: 1.3804 - val_auc: 0.9713\n","Epoch 405/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.4734 - auc: 0.9659 - val_loss: 1.3957 - val_auc: 0.9681\n","Epoch 406/10000\n","166/166 [==============================] - 15s 93ms/step - loss: 1.4736 - auc: 0.9659 - val_loss: 1.3871 - val_auc: 0.9690\n","Epoch 407/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4771 - auc: 0.9657 - val_loss: 1.3592 - val_auc: 0.9704\n","Epoch 408/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4742 - auc: 0.9660 - val_loss: 1.3949 - val_auc: 0.9699\n","Epoch 409/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4788 - auc: 0.9658 - val_loss: 1.3498 - val_auc: 0.9709\n","Epoch 410/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4706 - auc: 0.9662 - val_loss: 1.3506 - val_auc: 0.9704\n","Epoch 411/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4723 - auc: 0.9662 - val_loss: 1.3498 - val_auc: 0.9700\n","Epoch 412/10000\n","166/166 [==============================] - 16s 94ms/step - loss: 1.4779 - auc: 0.9658 - val_loss: 1.4010 - val_auc: 0.9700\n","Epoch 413/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4736 - auc: 0.9661 - val_loss: 1.3756 - val_auc: 0.9687\n","Epoch 414/10000\n","166/166 [==============================] - 15s 94ms/step - loss: 1.4744 - auc: 0.9659 - val_loss: 1.3813 - val_auc: 0.9699\n","Epoch 415/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4730 - auc: 0.9658 - val_loss: 1.4083 - val_auc: 0.9687\n","Epoch 416/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4740 - auc: 0.9657 - val_loss: 1.3730 - val_auc: 0.9709\n","Epoch 417/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4724 - auc: 0.9660 - val_loss: 1.3993 - val_auc: 0.9696\n","Epoch 418/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4755 - auc: 0.9658 - val_loss: 1.3965 - val_auc: 0.9687\n","Epoch 419/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4714 - auc: 0.9661 - val_loss: 1.3977 - val_auc: 0.9696\n","Epoch 420/10000\n","166/166 [==============================] - 16s 95ms/step - loss: 1.4703 - auc: 0.9662 - val_loss: 1.3756 - val_auc: 0.9718\n","Epoch 421/10000\n","166/166 [==============================] - 16s 96ms/step - loss: 1.4734 - auc: 0.9660 - val_loss: 1.3590 - val_auc: 0.9698\n","Epoch 422/10000\n","166/166 [==============================] - 17s 100ms/step - loss: 1.4709 - auc: 0.9661 - val_loss: 1.3570 - val_auc: 0.9725\n","Epoch 423/10000\n","166/166 [==============================] - 17s 101ms/step - loss: 1.4742 - auc: 0.9660 - val_loss: 1.3834 - val_auc: 0.9699\n","Epoch 424/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.4731 - auc: 0.9661 - val_loss: 1.3948 - val_auc: 0.9686\n","Epoch 425/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.4689 - auc: 0.9664 - val_loss: 1.3443 - val_auc: 0.9708\n","Epoch 426/10000\n","166/166 [==============================] - 17s 100ms/step - loss: 1.4729 - auc: 0.9660 - val_loss: 1.3771 - val_auc: 0.9698\n","Epoch 427/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4677 - auc: 0.9663 - val_loss: 1.3923 - val_auc: 0.9704\n","Epoch 428/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4705 - auc: 0.9661 - val_loss: 1.4014 - val_auc: 0.9691\n","Epoch 429/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4684 - auc: 0.9661 - val_loss: 1.3860 - val_auc: 0.9695\n","Epoch 430/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4655 - auc: 0.9661 - val_loss: 1.4143 - val_auc: 0.9680\n","Epoch 431/10000\n","166/166 [==============================] - 17s 100ms/step - loss: 1.4710 - auc: 0.9663 - val_loss: 1.3694 - val_auc: 0.9705\n","Epoch 432/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4653 - auc: 0.9665 - val_loss: 1.3749 - val_auc: 0.9695\n","Epoch 433/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4641 - auc: 0.9664 - val_loss: 1.3460 - val_auc: 0.9732\n","Epoch 434/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4655 - auc: 0.9661 - val_loss: 1.3792 - val_auc: 0.9704\n","Epoch 435/10000\n","166/166 [==============================] - 20s 123ms/step - loss: 1.4611 - auc: 0.9666 - val_loss: 1.3756 - val_auc: 0.9709\n","Epoch 436/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.4648 - auc: 0.9662 - val_loss: 1.3771 - val_auc: 0.9701\n","Epoch 437/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4631 - auc: 0.9665 - val_loss: 1.3951 - val_auc: 0.9681\n","Epoch 438/10000\n","166/166 [==============================] - 21s 129ms/step - loss: 1.4642 - auc: 0.9663 - val_loss: 1.3571 - val_auc: 0.9715\n","Epoch 439/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4606 - auc: 0.9666 - val_loss: 1.3908 - val_auc: 0.9692\n","Epoch 440/10000\n","166/166 [==============================] - 17s 101ms/step - loss: 1.4656 - auc: 0.9663 - val_loss: 1.3549 - val_auc: 0.9708\n","Epoch 441/10000\n","166/166 [==============================] - 17s 101ms/step - loss: 1.4666 - auc: 0.9662 - val_loss: 1.3686 - val_auc: 0.9701\n","Epoch 442/10000\n","166/166 [==============================] - 17s 101ms/step - loss: 1.4655 - auc: 0.9664 - val_loss: 1.3737 - val_auc: 0.9705\n","Epoch 443/10000\n","166/166 [==============================] - 16s 98ms/step - loss: 1.4623 - auc: 0.9665 - val_loss: 1.3826 - val_auc: 0.9685\n","Epoch 444/10000\n","166/166 [==============================] - 17s 100ms/step - loss: 1.4662 - auc: 0.9663 - val_loss: 1.3625 - val_auc: 0.9702\n","Epoch 445/10000\n","166/166 [==============================] - 17s 100ms/step - loss: 1.4665 - auc: 0.9663 - val_loss: 1.3558 - val_auc: 0.9727\n","Epoch 446/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4608 - auc: 0.9666 - val_loss: 1.4135 - val_auc: 0.9684\n","Epoch 447/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4616 - auc: 0.9664 - val_loss: 1.3520 - val_auc: 0.9707\n","Epoch 448/10000\n","166/166 [==============================] - 17s 102ms/step - loss: 1.4595 - auc: 0.9669 - val_loss: 1.3770 - val_auc: 0.9694\n","Epoch 449/10000\n","166/166 [==============================] - 17s 102ms/step - loss: 1.4617 - auc: 0.9668 - val_loss: 1.3591 - val_auc: 0.9706\n","Epoch 450/10000\n","166/166 [==============================] - 20s 123ms/step - loss: 1.4624 - auc: 0.9665 - val_loss: 1.3331 - val_auc: 0.9727\n","Epoch 451/10000\n","166/166 [==============================] - 17s 103ms/step - loss: 1.4565 - auc: 0.9668 - val_loss: 1.3524 - val_auc: 0.9716\n","Epoch 452/10000\n","166/166 [==============================] - 17s 101ms/step - loss: 1.4610 - auc: 0.9666 - val_loss: 1.3686 - val_auc: 0.9699\n","Epoch 453/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4597 - auc: 0.9667 - val_loss: 1.3815 - val_auc: 0.9688\n","Epoch 454/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4547 - auc: 0.9671 - val_loss: 1.3535 - val_auc: 0.9718\n","Epoch 455/10000\n","166/166 [==============================] - 17s 103ms/step - loss: 1.4595 - auc: 0.9665 - val_loss: 1.3612 - val_auc: 0.9699\n","Epoch 456/10000\n","166/166 [==============================] - 16s 99ms/step - loss: 1.4588 - auc: 0.9668 - val_loss: 1.3595 - val_auc: 0.9706\n","Epoch 457/10000\n","166/166 [==============================] - 17s 104ms/step - loss: 1.4573 - auc: 0.9667 - val_loss: 1.3121 - val_auc: 0.9739\n","Epoch 458/10000\n","166/166 [==============================] - 16s 97ms/step - loss: 1.4538 - auc: 0.9669 - val_loss: 1.3882 - val_auc: 0.9713\n","Epoch 459/10000\n","166/166 [==============================] - 17s 104ms/step - loss: 1.4515 - auc: 0.9670 - val_loss: 1.3650 - val_auc: 0.9713\n","Epoch 460/10000\n","166/166 [==============================] - 17s 102ms/step - loss: 1.4552 - auc: 0.9668 - val_loss: 1.3447 - val_auc: 0.9710\n","Epoch 461/10000\n","166/166 [==============================] - 17s 102ms/step - loss: 1.4566 - auc: 0.9667 - val_loss: 1.3617 - val_auc: 0.9707\n","Epoch 462/10000\n","166/166 [==============================] - 17s 101ms/step - loss: 1.4581 - auc: 0.9668 - val_loss: 1.3796 - val_auc: 0.9697\n","Epoch 463/10000\n","166/166 [==============================] - 17s 100ms/step - loss: 1.4538 - auc: 0.9670 - val_loss: 1.3470 - val_auc: 0.9720\n","Epoch 464/10000\n"," 32/166 [====>.........................] - ETA: 11s - loss: 1.4645 - auc: 0.9663"]}],"source":["history = model.fit(train_datagen.loader(),\n","                    batch_size=train_datagen.batch_size,\n","                    steps_per_epoch= train_datagen.get_len(),\n","                    initial_epoch=227,\n","                    epochs=10000,\n","                    validation_data=test_datagen.loader(),\n","                    validation_steps=test_datagen.get_len(),\n","                    validation_batch_size=test_datagen.batch_size,\n","                    callbacks=[callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cU0PZAry0cJ"},"outputs":[],"source":["#model.save_weights('gdrive/MyDrive/AIForYou/applications/tetris/training_model/checkpoint_epoch-4533_val_loss-1.3344.hdf5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxQY_0WrzARq"},"outputs":[],"source":["matrix = np.array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"]},{"cell_type":"code","source":["matrix.shape"],"metadata":{"id":"6X7Bd38KhJwp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x, y = next(train_datagen.loader())"],"metadata":{"id":"_JuHnDKnhifV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x[1, :, :, 0]"],"metadata":{"id":"8oU7XQ0uhmEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"jogNwKq8iLBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict()"],"metadata":{"id":"VvbWcS2IhLek"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyPhvKyTlm6I4Ydr6CMyB48Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}